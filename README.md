# CO2 Emissions Data Analysis

This project demonstrates how to build a complete data analysis pipeline using Python. The workflow includes web scraping, data cleaning, exploratory data analysis, and data visualization using real-world CO2 emissions data for the United States.

## Project Purpose

The purpose of this project is to:
- Practice web scraping using `requests` and `BeautifulSoup`
- Clean and preprocess raw data using `pandas`
- Analyze CO2 emission trends across different years and decades
- Visualize insights using `seaborn` with informative plots and data annotations

## Repository Contents

- `CO2_Emissions_Analysis.ipynb`  
  Jupyter Notebook containing:
  - Step-by-step code for scraping and cleaning the data
  - Four key data analysis questions answered
  - Visualizations of two results using Seaborn
  - Markdown cells for explanation and context

- `README.md`  
  Youâ€™re reading it! Provides an overview of the project and its structure.

## Data Source

All data was scraped from [Worldometer - U.S. CO2 Emissions](https://www.worldometers.info/co2-emissions/us-co2-emissions/), a statistics website that tracks global data in real time.

## Key Learnings

- How to programmatically collect and clean real-world data
- How to analyze time series environmental data
- How to create stylish and annotated data visualizations using Seaborn

---

